{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import umap\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df = pd.read_csv(\"/home/ubuntu/large-bascivi/exp_logs/v6/gene_exclusion/pred_embeddings.tsv\", sep=\"\\t\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(emb_df, x=\"umap_0\", y=\"umap_1\", color=\"standard_true_celltype\", width=1000, height=800)\n",
    "fig.update_traces(marker=dict(size=2, opacity=0.5,))\n",
    "fig\n",
    "\n",
    "fig.write_html(\"/home/ubuntu/large-bascivi/exp_logs/v6/gene_exclusion/embeddings_celltype.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(emb_df, x=\"umap_0\", y=\"umap_1\", color=\"study_name_display\", width=1000, height=800)\n",
    "fig.update_traces(marker=dict(size=2, opacity=0.5,))\n",
    "fig\n",
    "\n",
    "fig.write_html(\"/home/ubuntu/large-bascivi/exp_logs/v6/gene_exclusion/embeddings_study.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAScVI Models\n",
    "\n",
    "DIR = \"/home/ubuntu/large-bascivi/exp_logs/v6\"\n",
    "\n",
    "exp_logs = os.listdir(DIR)\n",
    "exps = []\n",
    "files = []\n",
    "\n",
    "for i,el in enumerate(exp_logs):\n",
    "    fname = os.path.join(DIR, el,'pred_embeddings.tsv')\n",
    "    \n",
    "    if os.path.exists(fname):\n",
    "        exps.append(el)\n",
    "        files.append(fname)\n",
    "\n",
    "# Sort on name guarantee matching files to study names\n",
    "\n",
    "exps = np.asarray(exps)\n",
    "files = np.asarray(files)\n",
    "\n",
    "inds = np.argsort(exps)\n",
    "\n",
    "exps = exps[inds]\n",
    "files = files[inds]\n",
    "cols = [\"embedding_\"+ str(i) for i in range(10)]\n",
    "dims = [10 for i in range(50)]\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up for KNI\n",
    "\n",
    "#df_embeddings = pd.read_csv(files[0])\n",
    "#df_embeddings = df_embeddings.join(df_embeddings_harmony.copy(), on='barcode',rsuffix='_') # scGPT\n",
    "\n",
    "df_embeddings = pd.read_csv(files[0], delimiter='\\t') # scVI / BAscVI / Harmony / Scanorama\n",
    "#df_embeddings[cols] = pca_vals # PCA\n",
    "\n",
    "#df_embeddings = df_embeddings.join(df_embeddings_harmony.copy(), on='barcode',rsuffix='_') # Seurat\n",
    "#cols = cols_list[0] # For bbknn\n",
    "\n",
    "cell_types = np.asarray(df_embeddings['standard_true_celltype'].astype('category').cat.codes,dtype=int)\n",
    "\n",
    "cat = df_embeddings['study_name'].astype('category')\n",
    "mapping = cat.cat.categories\n",
    "study_name = cat.cat.codes\n",
    "studies = list(range(len(mapping)))\n",
    "\n",
    "results = pd.DataFrame(np.zeros((len(studies),exps.shape[0])),index=studies,columns=exps)\n",
    "\n",
    "print(\"Starting Loop\")\n",
    "\n",
    "# KNI loop\n",
    "\n",
    "for ii,fname in enumerate(files):\n",
    "    \n",
    "    #df_embeddings = pd.read_csv(files[0])   \n",
    "    #df_embeddings = df_embeddings.join(df_embeddings_harmony.copy(), on='barcode',rsuffix='_') # scGPT \n",
    "\n",
    "    df_embeddings = pd.read_csv(fname,delimiter='\\t') # scVI / BAscVI / Harmony / Scanorama\n",
    "    \n",
    "    #df_embeddings[cols] = pca_vals # PCA\n",
    "    #df_embeddings = df_embeddings.join(df_embeddings_harmony.copy(), on=index_names[ii],rsuffix='_') # Seurat\n",
    "    \n",
    "    #cols = cols_list[ii]\n",
    "    \n",
    "    for i in range(dims[ii]):\n",
    "        df_embeddings[cols[i]] = df_embeddings[cols[i]] - np.mean(df_embeddings[cols[i]])\n",
    "        (q1,q2) = np.quantile(df_embeddings[cols[i]],[0.25,0.75])\n",
    "        df_embeddings[cols[i]] = df_embeddings[cols[i]]/(q2-q1)\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=50) # 25 used for csv file\n",
    "    \n",
    "    cell_types = np.asarray(df_embeddings['standard_true_celltype'].astype('category').cat.codes,dtype=int)\n",
    "    cat = df_embeddings['study_name'].astype('category')\n",
    "    mapping = cat.cat.categories\n",
    "    study_name = cat.cat.codes\n",
    "\n",
    "    classifier.fit(df_embeddings[cols[:dims[ii]]], cell_types)\n",
    "\n",
    "    vals = classifier.kneighbors(n_neighbors=50)\n",
    "\n",
    "    knn_ct = cell_types[vals[1].flatten()].reshape(vals[1].shape)\n",
    "    knn_exp = study_name.iloc[vals[1].flatten()].values.reshape(vals[1].shape)\n",
    "    \n",
    "    exp_mat = np.repeat(np.expand_dims(study_name,1),knn_exp.shape[1],axis=1)\n",
    "    \n",
    "    self_mask = knn_exp != exp_mat\n",
    "    cutoff = np.sum(np.logical_not(self_mask),axis=1)\n",
    "\n",
    "    acc = {study:0 for study in studies}\n",
    "    batch = {study:0 for study in studies}\n",
    "    kni = {study:0 for study in studies}\n",
    "\n",
    "    mask_1 = cutoff < 40\n",
    "\n",
    "    for i in range(df_embeddings.shape[0]):\n",
    "        if mask_1[i]:\n",
    "            acc[study_name[i]]\n",
    "            pred = np.argmax(np.bincount(knn_ct[i,:][self_mask[i,:]]))\n",
    "            batch[study_name[i]] +=1\n",
    "            if pred == cell_types[i]:\n",
    "                kni[study_name[i]] +=1\n",
    "    \n",
    "    print(fname)\n",
    "    total = 0\n",
    "    for study in studies:\n",
    "        print(mapping[study], '\\t', kni[study])\n",
    "        \n",
    "        results[exps[ii]].loc[study] = kni[study]\n",
    "        total += kni[study]\n",
    "    print(\"Total:  \", total, \" Cell N:  \", df_embeddings.shape[0],\" % Acc: \" , total/df_embeddings.shape[0])\n",
    "    print()\n",
    "    \n",
    "    # Break down into accuracy vs. batch / kbet\n",
    "\n",
    "    print(\"Batch breadkdown:\")\n",
    "    print()\n",
    "    \n",
    "    for study in studies:\n",
    "        print(mapping[study], '\\t', batch[study])\n",
    "    \n",
    "    print()\n",
    "    print(\"Accuracy breadkdown:\")\n",
    "    print()\n",
    "    \n",
    "    for study in studies:\n",
    "        \n",
    "        classifier = KNeighborsClassifier(n_neighbors=10) # 25 used for csv file\n",
    "        \n",
    "        study_mask = mapping[study] == df_embeddings['study_name']\n",
    "        \n",
    "        classifier.fit(df_embeddings[cols[:dims[ii]]].values[np.logical_not(study_mask),:], \n",
    "                       cell_types[np.logical_not(study_mask)])\n",
    "        \n",
    "        pred = classifier.predict(df_embeddings[cols[:dims[ii]]].values[study_mask,:])\n",
    "        acc[study] = np.sum(pred == cell_types[study_mask])\n",
    "        \n",
    "        print(mapping[study],'\\t',acc[study])\n",
    "        \n",
    "    print()\n",
    "\n",
    "#results.to_csv(\"KNI_results/baScVI_ScVI_lp.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "classifier = KNeighborsClassifier(n_neighbors=10) # 25 used for csv file\n",
    "\n",
    "study_mask = mapping[study] == df_embeddings['study_name']\n",
    "print(study)\n",
    "classifier.fit(df_embeddings[cols[:dims[ii]]].values[np.logical_not(study_mask),:], \n",
    "               cell_types[np.logical_not(study_mask)])\n",
    "\n",
    "pred = classifier.predict(df_embeddings[cols[:dims[ii]]].values[study_mask,:])\n",
    "acc[study] = np.sum(pred == cell_types[study_mask])\n",
    "\n",
    "print(acc[study])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up for KNI with FOXP3+ labels\n",
    "\n",
    "df_embeddings = pd.read_csv(files[0],delimiter='\\t')\n",
    "\n",
    "#cols = [\"embedding_\"+ str(i) for i in range(10)]\n",
    "\n",
    "cols = [\"PC_\"+ str(i+1) for i in range(50)] # Harmony\n",
    "df_embeddings[cols] = pca_vals # PCA\n",
    "    \n",
    "#df_embeddings = df_embeddings.join(df_embeddings_harmony.copy(), on='barcode',rsuffix='_') # Seurat \n",
    "\n",
    "#cols = [\"X_umap10_bbknn_harm_study\"+ str(i) for i in range(10)] # bbKNN\n",
    "#cols = [\"harmony_embedding\"+ str(i) for i in range(50)]\n",
    "#cols = [\"harmony_sample_embedding\"+ str(i) for i in range(10)]\n",
    "\n",
    "dims = [10]\n",
    "\n",
    "df_names = pd.read_csv('foxp3_labels.csv')\n",
    "df_names = df_names.set_index('barcode')\n",
    "\n",
    "df_embeddings = df_embeddings.join(df_names, on='barcode',rsuffix='_FOXP3')\n",
    "cell_types = np.asarray(df_embeddings['standard_true_celltype_FOXP3'].astype('category').cat.codes,dtype=int)\n",
    "\n",
    "cat = df_embeddings['standard_true_celltype_FOXP3'].astype('category')\n",
    "mapping_cell = cat.cat.categories\n",
    "\n",
    "cat = df_embeddings['study_name'].astype('category')\n",
    "mapping = cat.cat.categories\n",
    "study_name = cat.cat.codes\n",
    "\n",
    "studies = list(range(len(mapping)))\n",
    "\n",
    "results = pd.DataFrame(np.zeros((len(mapping_cell),exps.shape[0])),index=mapping_cell,columns=exps)\n",
    "\n",
    "print(\"Starting Loop\")\n",
    "\n",
    "# KNI loop\n",
    "\n",
    "#for ii,fname in enumerate(['./baScVI_ScVI_hp_lrx0.5/BaScVI_4L_Both/train_embeddings.tsv',\n",
    "#                           './baScVI_ScVI_lp/ScVI_4L_Both/train_embeddings.tsv',\n",
    "#                           './baScVI_ScVI_hp/ScVI_2L_Sample/train_embeddings.tsv',\n",
    "#                           'vae_scvi/VAE_MSE/train_embeddings.tsv']):\n",
    "for ii,fname in enumerate([files[0]]):\n",
    "\n",
    "    df_embeddings = pd.read_csv(fname,delimiter='\\t')\n",
    "    #df_embeddings = df_embeddings.join(df_embeddings_harmony.copy(), on=index_names[ii],rsuffix='_') # Seurat \n",
    "\n",
    "    cols = [\"PC_\"+ str(i+1) for i in range(50)] # Harmony\n",
    "    df_embeddings[cols] = pca_vals # PCA\n",
    "\n",
    "    mask = df_embeddings['study_name'] != 'external_wu_natgenet_2021_34493872'\n",
    "    df_embeddings = df_embeddings[mask]\n",
    "    \n",
    "    df_names = pd.read_csv('foxp3_labels.csv')\n",
    "    df_names = df_names.set_index('barcode')\n",
    "    df_embeddings = df_embeddings.join(df_names, on='barcode',rsuffix='_FOXP3')\n",
    "    print(df_embeddings.shape)\n",
    "    \n",
    "    cell_types = np.asarray(df_embeddings['standard_true_celltype_FOXP3'].astype('category').cat.codes,dtype=int)\n",
    "    cell_types[cell_types==-1] = 0 #sets 30 cells to 0 for Harmony evaluation\n",
    "    \n",
    "    cat = df_embeddings['study_name'].astype('category')\n",
    "    mapping = cat.cat.categories\n",
    "    study_name = cat.cat.codes\n",
    "    \n",
    "    # Normalization to standard local distance spread for RbNI\n",
    "\n",
    "    for i in range(dims[ii]):\n",
    "        df_embeddings[cols[i]] = df_embeddings[cols[i]] - np.mean(df_embeddings[cols[i]])\n",
    "        (q1,q2) = np.quantile(df_embeddings[cols[i]],[0.25,0.75])\n",
    "        df_embeddings[cols[i]] = df_embeddings[cols[i]]/(q2-q1)\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=50)\n",
    "    classifier.fit(df_embeddings[cols], cell_types)\n",
    "\n",
    "    vals = classifier.kneighbors(n_neighbors=50)\n",
    "\n",
    "    knn_ct = cell_types[vals[1].flatten()].reshape(vals[1].shape)\n",
    "    knn_exp = study_name.iloc[vals[1].flatten()].values.reshape(vals[1].shape)\n",
    "    \n",
    "    exp_mat = np.repeat(np.expand_dims(study_name,1),knn_exp.shape[1],axis=1)\n",
    "    \n",
    "    self_mask = knn_exp != exp_mat\n",
    "    cutoff = np.sum(np.logical_not(self_mask),axis=1)\n",
    "\n",
    "    acc = {cell_type:0 for cell_type in mapping_cell}\n",
    "\n",
    "    mask_1 = cutoff < 40\n",
    "\n",
    "    for i in range(df_embeddings.shape[0]):\n",
    "        if mask_1[i]:\n",
    "            pred = np.argmax(np.bincount(knn_ct[i,:][self_mask[i,:]]))\n",
    "            if pred == cell_types[i]:\n",
    "                acc[mapping_cell[cell_types[i]]] +=1\n",
    "                \n",
    "    print(fname)\n",
    "    total = 0\n",
    "    for cell_type in mapping_cell:\n",
    "        \n",
    "        print(cell_type, '\\t', acc[cell_type])\n",
    "        \n",
    "        results[exps[ii]].loc[cell_type] = acc[cell_type]\n",
    "        total += acc[cell_type]\n",
    "    print(\"Total:  \", total)\n",
    "    print()\n",
    "\n",
    "results.to_csv(\"KNI_scanorama_foxp3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on Wu holdout study\n",
    "\n",
    "files = ['holdout/BA_scVI_1k_holdout/train_embeddings.tsv']\n",
    "\n",
    "# Set up for KNI\n",
    "\n",
    "df_embeddings = pd.read_csv(files[0],delimiter='\\t')         \n",
    "\n",
    "cols = [\"embedding_\"+ str(i) for i in range(10)]\n",
    "dims = [10]\n",
    "\n",
    "mask_tissue = df_embeddings['study_name'] != 'external_macfib_schuster_2020_000000'\n",
    "df_embeddings = df_embeddings[mask_tissue]\n",
    "\n",
    "cell_types = np.asarray(df_embeddings['standard_true_celltype'].astype('category').cat.codes,dtype=int)\n",
    "\n",
    "cat = df_embeddings['study_name'].astype('category')\n",
    "mapping = cat.cat.categories\n",
    "study_name = cat.cat.codes\n",
    "studies = list(range(len(mapping)))\n",
    "\n",
    "results = pd.DataFrame(np.zeros((len(studies),exps.shape[0])),index=studies,columns=exps)\n",
    "\n",
    "print(\"Starting Loop\")\n",
    "\n",
    "# KNI loop\n",
    "\n",
    "for ii,fname in enumerate(files):\n",
    "    \n",
    "\n",
    "    df_embeddings = pd.read_csv(fname,delimiter='\\t') # scVI / BAscVI / Harmony / Scanorama\n",
    "    \n",
    "    mask_tissue = df_embeddings['study_name'] != 'external_macfib_schuster_2020_000000'\n",
    "    df_embeddings = df_embeddings[mask_tissue]\n",
    "    \n",
    "    for i in range(dims[ii]):\n",
    "        df_embeddings[cols[i]] = df_embeddings[cols[i]] - np.mean(df_embeddings[cols[i]])\n",
    "        (q1,q2) = np.quantile(df_embeddings[cols[i]],[0.25,0.75])\n",
    "        df_embeddings[cols[i]] = df_embeddings[cols[i]]/(q2-q1)\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=50) # 25 used for csv file\n",
    "    \n",
    "    cell_types = np.asarray(df_embeddings['standard_true_celltype'].astype('category').cat.codes,dtype=int)\n",
    "    cat = df_embeddings['study_name'].astype('category')\n",
    "    mapping = cat.cat.categories\n",
    "    study_name = cat.cat.codes\n",
    "\n",
    "    classifier.fit(df_embeddings[cols[:dims[ii]]], cell_types)\n",
    "\n",
    "    vals = classifier.kneighbors(n_neighbors=50)\n",
    "\n",
    "    knn_ct = cell_types[vals[1].flatten()].reshape(vals[1].shape)\n",
    "    knn_exp = study_name.iloc[vals[1].flatten()].values.reshape(vals[1].shape)\n",
    "    \n",
    "    exp_mat = np.repeat(np.expand_dims(study_name,1),knn_exp.shape[1],axis=1)\n",
    "    \n",
    "    self_mask = knn_exp != exp_mat\n",
    "    cutoff = np.sum(np.logical_not(self_mask),axis=1)\n",
    "\n",
    "    acc = {study:0 for study in studies}\n",
    "    batch = {study:0 for study in studies}\n",
    "    kni = {study:0 for study in studies}\n",
    "\n",
    "    mask_1 = cutoff < 40\n",
    "\n",
    "    for i in range(df_embeddings.shape[0]):\n",
    "        if mask_1[i]:\n",
    "            acc[study_name.iloc[i]]\n",
    "            pred = np.argmax(np.bincount(knn_ct[i,:][self_mask[i,:]]))\n",
    "            batch[study_name.iloc[i]] +=1\n",
    "            if pred == cell_types[i]:\n",
    "                kni[study_name.iloc[i]] +=1\n",
    "    \n",
    "    print(fname)\n",
    "    total = 0\n",
    "    for study in studies:\n",
    "        print(mapping[study], '\\t', kni[study])\n",
    "        \n",
    "        results[exps[ii]].loc[study] = kni[study]\n",
    "        total += kni[study]\n",
    "    print(\"Total:  \", total, \" Cell N:  \", df_embeddings.shape[0],\" % Acc: \" , total/df_embeddings.shape[0])\n",
    "    print()\n",
    "    \n",
    "    # Break down into accuracy vs. batch / kbet\n",
    "\n",
    "    print(\"Batch breadkdown:\")\n",
    "    print()\n",
    "    \n",
    "    for study in studies:\n",
    "        print(mapping[study], '\\t', batch[study])\n",
    "    \n",
    "    print()\n",
    "    print(\"Accuracy breadkdown:\")\n",
    "    print()\n",
    "    \n",
    "    for study in studies:\n",
    "        \n",
    "        classifier = KNeighborsClassifier(n_neighbors=10) # 25 used for csv file\n",
    "        \n",
    "        study_mask = mapping[study] == df_embeddings['study_name']\n",
    "        \n",
    "        classifier.fit(df_embeddings[cols[:dims[ii]]].values[np.logical_not(study_mask),:], \n",
    "                       cell_types[np.logical_not(study_mask)])\n",
    "        \n",
    "        pred = classifier.predict(df_embeddings[cols[:dims[ii]]].values[study_mask,:])\n",
    "        acc[study] = np.sum(pred == cell_types[study_mask])\n",
    "        \n",
    "        print(mapping[study],'\\t',acc[study])\n",
    "        \n",
    "    print()\n",
    "\n",
    "#results.to_csv(\"KNI_results/baScVI_ScVI_lp.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings = pd.read_csv(files[0],delimiter='\\t')\n",
    "cols = [\"harmony_sample_embedding\"+ str(i) for i in range(50)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on Wu holdout studies\n",
    "\n",
    "files = ['holdout/BA_scVI_1k_holdout/train_embeddings.tsv']\n",
    "\n",
    "# Set up for KNI\n",
    "\n",
    "df_embeddings = pd.read_csv(files[0],delimiter='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_internal = df_embeddings['study_name'] != 'external_macfib_schuster_2020_000000'\n",
    "df_embeddings = df_embeddings[mask_internal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii,fname in enumerate(files):\n",
    "    \n",
    "    #df_embeddings = pd.read_csv(files[0])   \n",
    "    #df_embeddings = df_embeddings.join(df_embeddings_harmony.copy(), on='barcode',rsuffix='_') # scGPT \n",
    "\n",
    "    df_embeddings = pd.read_csv(fname,delimiter='\\t') # scVI / BAscVI / Harmony / Scanorama\n",
    "    snlist = list(df_embeddings['study_name'].unique())\n",
    "    snlist.sort()\n",
    "    for sn in snlist:\n",
    "        \n",
    "        print(sn, np.sum(sn == df_embeddings['study_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
